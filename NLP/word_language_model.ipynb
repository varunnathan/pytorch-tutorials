{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing - dictionary and input iterator\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "    \n",
    "    \n",
    "class Corpus(object):\n",
    "    def __init__(self, data_dir='wikitext-2/'):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(\n",
    "            data_dir, 'wiki.train.tokens'))\n",
    "        self.test = self.tokenize(os.path.join(\n",
    "            data_dir, 'wiki.test.tokens'))\n",
    "        self.valid = self.tokenize(os.path.join(\n",
    "            data_dir, 'wiki.valid.tokens'))\n",
    "        \n",
    "    def tokenize(self, fn):\n",
    "        assert os.path.isfile(fn)\n",
    "        with open(fn, 'r') as f:\n",
    "            n_tokens = 0\n",
    "            tokens = []\n",
    "            for line in f:\n",
    "                words = line.strip().split()\n",
    "                if not words:\n",
    "                    continue\n",
    "                words += ['<eos>']\n",
    "                n_tokens += len(words)\n",
    "                for word in words:\n",
    "                    tokens.append(self.dictionary.add_word(word))\n",
    "        tokens = torch.LongTensor(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(data_dir='wikitext-2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens:\n",
      "Train:  2075677\n",
      "Valid:  216347\n",
      "Test:   244102\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\")\n",
    "print(\"Train: \", len(corpus.train))\n",
    "print(\"Valid: \", len(corpus.valid))\n",
    "print(\"Test:  \", len(corpus.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 1144,    9,    0,    4, 1144,    9,   26,  147,  858])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(corpus.dictionary.word2idx['<eos>'])\n",
    "print(corpus.dictionary.word2idx['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(source, bsz):\n",
    "    nbatch = source.size(0) // bsz\n",
    "    source = source.narrow(0, 0, nbatch * bsz)\n",
    "    source = source.view(bsz, -1).t().contiguous()\n",
    "    return source.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 10\n",
    "train_data = batchify(corpus.train, 20)\n",
    "val_data = batchify(corpus.valid, 10)\n",
    "test_data = batchify(corpus.test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([103783, 20]), torch.Size([24410, 10]), torch.Size([21634, 10]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers,\n",
    "                 dropout=0.5, tie_weights=False):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        \n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers,\n",
    "                                             dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}\n",
    "                nonlinearity = nonlinearity[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError( \"\"\"An invalid option for `--model`\n",
    "                                  was supplied, options are\n",
    "                                  ['LSTM', 'GRU', 'RNN_TANH',\n",
    "                                  'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(ninp, nhid, nlayers,\n",
    "                              nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        \n",
    "        if tie_weights:\n",
    "            assert nhid == ninp\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.ninp = ninp\n",
    "        self.nlayers = nlayers\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        print(input.shape)\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        print(emb.shape)\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        print(output.shape, '\\t', len(hidden))\n",
    "        output = self.drop(output)\n",
    "        #print(output.shape)\n",
    "        decoded_output = self.decoder(\n",
    "            output.view(output.size(0) * output.size(1), output.size(2)))\n",
    "        print(decoded_output.shape)\n",
    "        return decoded_output, hidden\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
    "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
    "        else:\n",
    "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tokens:  33278\n"
     ]
    }
   ],
   "source": [
    "# model parameters\n",
    "ntokens = len(corpus.dictionary.word2idx)\n",
    "EMB_SIZE = 200\n",
    "NHID = 300\n",
    "NLAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "LR = 20\n",
    "CLIP = 0.25\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 20\n",
    "EVAL_BATCH_SIZE = 10\n",
    "BPTT = 35\n",
    "TIED = False\n",
    "SEED = 1\n",
    "LOG_INTERVAL = 200\n",
    "SAVE = 'model.pt'\n",
    "ONNX_EXPORT = ''\n",
    "print('# tokens: ', ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel('LSTM', ntokens, EMB_SIZE, NHID, NLAYERS, DROPOUT,\n",
    "                 TIED).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (encoder): Embedding(33278, 200)\n",
       "  (rnn): LSTM(200, 300, num_layers=2, dropout=0.2)\n",
       "  (decoder): Linear(in_features=300, out_features=33278, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 20, 300]), torch.Size([2, 20, 300]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = model.init_hidden(BATCH_SIZE)\n",
    "hidden[0].shape, hidden[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = repackage_hidden(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, bptt, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    #print(seq_len)\n",
    "    x = source[i: i+seq_len]\n",
    "    y = source[i+1: i+1+seq_len].view(-1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_batch(train_data, BPTT, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([35, 20]), torch.Size([700]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,    13, 10525,   664,  5764,    13,    17,   209, 14628,     9,\n",
       "          2989,   246,  2705, 22197,   361,  1699,  1129,  1345,   119,  2143],\n",
       "        [    1, 10606,    43,   448,    13,    37, 22199,    61,  4037,    13,\n",
       "            16,   935,    37,  3840,  1340,    15,    23,     6, 32652,    13],\n",
       "        [    2,   664,  6936,    37,   766, 23079,  1237,  1100, 20894,    17,\n",
       "            83,   168,    88,    15,     9,  5103,  6318,  1862,   151,   162],\n",
       "        [    3,  1829,   440,   765, 16388,    13,  1794,    16,    13, 18453,\n",
       "         19900,   631,    17,   860,    13,   284,    15,   639,    17,  8276],\n",
       "        [    0,    22,    35, 18750,    37,    37,    16,  6659,    17,    16,\n",
       "            13,    16,  4597,    17, 27572,  2790,  3084,   147, 28182,  2313],\n",
       "        [    4,   704,  1756,   664,  8944,   293,    17,  4318,  2576, 27981,\n",
       "            27,    46,   370, 11199,  1036,    17,    13, 24897,   168,    46],\n",
       "        [    5,   333,    13,  1270,  9172,  1227,   289,    61,   131,  5437,\n",
       "          4242,    37,  1193, 24300,   492,  7404,    17,    15,  5132,   119],\n",
       "        [    6,    17,    17,    15,  1978,  2135,    13,    15,   284,   151,\n",
       "           722,   496,   529,    13, 10012,    13,  6498,  1192,   271,    27],\n",
       "        [    1, 10323,  6834,  1642,    10,    15, 22196,     9,   222, 27977,\n",
       "          4458, 10990,  7350,    17,     9, 13917,   669,  5211,    23,     9],\n",
       "        [    7,    15,   529, 12489, 21356,   652,  3107,   131,  3394, 13225,\n",
       "            37,    27,   147, 29681,   638,  5207,    16,    13,  7610,   911],\n",
       "        [    8,   652,    27,   664, 21120,    17,   423,  9629,   639,    17,\n",
       "         11113, 16484,  3069,  2524,   151,    17, 17620,    27,    16,    43],\n",
       "        [    9,   357,  2709,  6229,  5158,    59,  1517,    35,    27,  5170,\n",
       "            43,  1470, 12289,   293,  1986, 31575,  4918,  1295,    17,    17],\n",
       "        [    2,  2520,    16,   119,    13,  2879,    59,    27,  2819,    16,\n",
       "         15068,  1521,    43,   278,  4737,  2709, 17387, 22814, 29289,  3710],\n",
       "        [   10,    33,   722, 18692,     9,    17,   271,  6670,    16, 20166,\n",
       "            13,    16,  7559,   307,  2911,   131,  2099,   284,    43,    37],\n",
       "        [   11,   284,  3467,    13,    13,  2058,    13,    43,  1145,    43,\n",
       "           321, 14802,    16,    93,    22, 18056,    15,     9, 13379,    17],\n",
       "        [    8,   357,    15,    37,     9,  4556,   162,    17, 27001,   147,\n",
       "          8709,   128,  1139,    17,   578,   440,     9,  7179,   128,  1159],\n",
       "        [   12,  1496,     4,   278,    37,  7349, 22196,  8278,    15, 27982,\n",
       "            43,  1250,  2981,  2036,   195,   293,    78,    16,  6272,    13],\n",
       "        [   13,   449,    83,    27,   900,   128,   128,    37,  2853,    30,\n",
       "          6169,   449,    15,   221,   190,  8704,  2098,    61,    13,   119],\n",
       "        [   14,  5181,    59,  1944,    16, 23080, 22179, 12376,  1402,   635,\n",
       "            37,   532,     4, 12079, 31212,  6712,  1839, 32334,    43,    27],\n",
       "        [   15,    13,  1940,  2825,  5206,    37,   131,  6714,    78,  3458,\n",
       "          2440,    17,     0,   114,    37,   131,  3776,    13,   169,     9],\n",
       "        [    1,    17,  2224,   262,  6253,  8034, 13574,  7121,     6,   357,\n",
       "            13,  1003,     0,    17, 21760,    22,  2584,    17,    39,    37],\n",
       "        [   16,  1207,  1223,  4725,  5158,    16,    93,  8502,  2471, 26112,\n",
       "          2334,     9, 17345, 24300, 31220,  9347,    43,  1844,    17, 14415],\n",
       "        [   17,  1870,    43,    15,    19,   357,    47,    15, 15732,    23,\n",
       "            15,    37,     0,  4739,  3321,    23,   958, 24897,   578,    16],\n",
       "        [   18,    43, 10525,    83,    15,  3220,   271,  7402,   310,    61,\n",
       "          2543, 15501,     0,    30,    17,  1129,    37,    13,    29,   912],\n",
       "        [    7,  1809,   664,   417,   652,  2004,    39,   792,  7254,   772,\n",
       "          5660, 28826,     4,  4142,  2058,    23, 15781,    37,    16,   151],\n",
       "        [   19,    13, 15186,  6396,  2723,    13,    27,    13,    13, 20781,\n",
       "            17,    13,    83,    39,    13,  1023,  2098, 26379,  1357,    78],\n",
       "        [   13, 10314,    13,  4164,  2976, 23079,  2923,  5788,   113,     9,\n",
       "          1242,   166,  6495,    27,  4798,   745,  1839,    13,    16,    24],\n",
       "        [   20,   144,  2214,   131,    13, 18202,    13,   899, 27002, 27959,\n",
       "           826,    43,  3904, 22197,    61,    17,  2772,    17,    17,    17],\n",
       "        [   21,    27,   401,  3212,  6462,    13,    37,    78,    37,    61,\n",
       "          4312,  2333,  4011,    37,  1288, 15718, 13753,  6907, 29289,  2786],\n",
       "        [   22,  1426,    43,    22,    26,    43,    17,  8180,     9,    15,\n",
       "         28680,    15,    30,    27, 10993,  1104,    15,  8990,  7168,    16],\n",
       "        [   23,    30, 15178, 11996,  5140,    86, 24277,    93,   972,    83,\n",
       "            37,  9259,    43, 13499,  1290, 14584,     4,  6608,    13,    17],\n",
       "        [    1,  3022,   128,    37,    23,    15,   664,    17,   466,  8854,\n",
       "            17,   479,   284,  2933,  4326,    15,     0,  1395,    22,  3200],\n",
       "        [    2,   910,    37,  6285,   222, 18202,  1324,  3545,    39,    16,\n",
       "           193,    52,   147,    16,    78,     4,     0,    23,   209, 16509],\n",
       "        [    3,  4781,   225,   544,    16,   131,    22,  1364, 26994, 14316,\n",
       "            16,   496,  3069,  4895,   593,   652,     9,   147,   630,    15],\n",
       "        [   24,    15,  2218,    22,    17,    17, 21955,    22, 26995,    13,\n",
       "         14978,  3507,    16,  1839, 12850,    17,     0, 24897,   611,     4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1, 10606,    43,   448,    13,    37, 22199,    61,  4037,    13,\n",
       "           16,   935,    37,  3840,  1340,    15,    23,     6, 32652,    13,\n",
       "            2,   664,  6936,    37,   766, 23079,  1237,  1100, 20894,    17,\n",
       "           83,   168,    88,    15,     9,  5103,  6318,  1862,   151,   162,\n",
       "            3,  1829,   440,   765, 16388,    13,  1794,    16,    13, 18453,\n",
       "        19900,   631,    17,   860,    13,   284,    15,   639,    17,  8276,\n",
       "            0,    22,    35, 18750,    37,    37,    16,  6659,    17,    16,\n",
       "           13,    16,  4597,    17, 27572,  2790,  3084,   147, 28182,  2313,\n",
       "            4,   704,  1756,   664,  8944,   293,    17,  4318,  2576, 27981,\n",
       "           27,    46,   370, 11199,  1036,    17,    13, 24897,   168,    46,\n",
       "            5,   333,    13,  1270,  9172,  1227,   289,    61,   131,  5437,\n",
       "         4242,    37,  1193, 24300,   492,  7404,    17,    15,  5132,   119,\n",
       "            6,    17,    17,    15,  1978,  2135,    13,    15,   284,   151,\n",
       "          722,   496,   529,    13, 10012,    13,  6498,  1192,   271,    27,\n",
       "            1, 10323,  6834,  1642,    10,    15, 22196,     9,   222, 27977,\n",
       "         4458, 10990,  7350,    17,     9, 13917,   669,  5211,    23,     9,\n",
       "            7,    15,   529, 12489, 21356,   652,  3107,   131,  3394, 13225,\n",
       "           37,    27,   147, 29681,   638,  5207,    16,    13,  7610,   911,\n",
       "            8,   652,    27,   664, 21120,    17,   423,  9629,   639,    17,\n",
       "        11113, 16484,  3069,  2524,   151,    17, 17620,    27,    16,    43,\n",
       "            9,   357,  2709,  6229,  5158,    59,  1517,    35,    27,  5170,\n",
       "           43,  1470, 12289,   293,  1986, 31575,  4918,  1295,    17,    17,\n",
       "            2,  2520,    16,   119,    13,  2879,    59,    27,  2819,    16,\n",
       "        15068,  1521,    43,   278,  4737,  2709, 17387, 22814, 29289,  3710,\n",
       "           10,    33,   722, 18692,     9,    17,   271,  6670,    16, 20166,\n",
       "           13,    16,  7559,   307,  2911,   131,  2099,   284,    43,    37,\n",
       "           11,   284,  3467,    13,    13,  2058,    13,    43,  1145,    43,\n",
       "          321, 14802,    16,    93,    22, 18056,    15,     9, 13379,    17,\n",
       "            8,   357,    15,    37,     9,  4556,   162,    17, 27001,   147,\n",
       "         8709,   128,  1139,    17,   578,   440,     9,  7179,   128,  1159,\n",
       "           12,  1496,     4,   278,    37,  7349, 22196,  8278,    15, 27982,\n",
       "           43,  1250,  2981,  2036,   195,   293,    78,    16,  6272,    13,\n",
       "           13,   449,    83,    27,   900,   128,   128,    37,  2853,    30,\n",
       "         6169,   449,    15,   221,   190,  8704,  2098,    61,    13,   119,\n",
       "           14,  5181,    59,  1944,    16, 23080, 22179, 12376,  1402,   635,\n",
       "           37,   532,     4, 12079, 31212,  6712,  1839, 32334,    43,    27,\n",
       "           15,    13,  1940,  2825,  5206,    37,   131,  6714,    78,  3458,\n",
       "         2440,    17,     0,   114,    37,   131,  3776,    13,   169,     9,\n",
       "            1,    17,  2224,   262,  6253,  8034, 13574,  7121,     6,   357,\n",
       "           13,  1003,     0,    17, 21760,    22,  2584,    17,    39,    37,\n",
       "           16,  1207,  1223,  4725,  5158,    16,    93,  8502,  2471, 26112,\n",
       "         2334,     9, 17345, 24300, 31220,  9347,    43,  1844,    17, 14415,\n",
       "           17,  1870,    43,    15,    19,   357,    47,    15, 15732,    23,\n",
       "           15,    37,     0,  4739,  3321,    23,   958, 24897,   578,    16,\n",
       "           18,    43, 10525,    83,    15,  3220,   271,  7402,   310,    61,\n",
       "         2543, 15501,     0,    30,    17,  1129,    37,    13,    29,   912,\n",
       "            7,  1809,   664,   417,   652,  2004,    39,   792,  7254,   772,\n",
       "         5660, 28826,     4,  4142,  2058,    23, 15781,    37,    16,   151,\n",
       "           19,    13, 15186,  6396,  2723,    13,    27,    13,    13, 20781,\n",
       "           17,    13,    83,    39,    13,  1023,  2098, 26379,  1357,    78,\n",
       "           13, 10314,    13,  4164,  2976, 23079,  2923,  5788,   113,     9,\n",
       "         1242,   166,  6495,    27,  4798,   745,  1839,    13,    16,    24,\n",
       "           20,   144,  2214,   131,    13, 18202,    13,   899, 27002, 27959,\n",
       "          826,    43,  3904, 22197,    61,    17,  2772,    17,    17,    17,\n",
       "           21,    27,   401,  3212,  6462,    13,    37,    78,    37,    61,\n",
       "         4312,  2333,  4011,    37,  1288, 15718, 13753,  6907, 29289,  2786,\n",
       "           22,  1426,    43,    22,    26,    43,    17,  8180,     9,    15,\n",
       "        28680,    15,    30,    27, 10993,  1104,    15,  8990,  7168,    16,\n",
       "           23,    30, 15178, 11996,  5140,    86, 24277,    93,   972,    83,\n",
       "           37,  9259,    43, 13499,  1290, 14584,     4,  6608,    13,    17,\n",
       "            1,  3022,   128,    37,    23,    15,   664,    17,   466,  8854,\n",
       "           17,   479,   284,  2933,  4326,    15,     0,  1395,    22,  3200,\n",
       "            2,   910,    37,  6285,   222, 18202,  1324,  3545,    39,    16,\n",
       "          193,    52,   147,    16,    78,     4,     0,    23,   209, 16509,\n",
       "            3,  4781,   225,   544,    16,   131,    22,  1364, 26994, 14316,\n",
       "           16,   496,  3069,  4895,   593,   652,     9,   147,   630,    15,\n",
       "           24,    15,  2218,    22,    17,    17, 21955,    22, 26995,    13,\n",
       "        14978,  3507,    16,  1839, 12850,    17,     0, 24897,   611,     4,\n",
       "           25,    83,    15, 11272, 11766,    59,    17,    27,    15,    93,\n",
       "        28694,   147,  1162,  2376,    22,  1763,     0,    61, 13379,  8276])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 20])\n",
      "torch.Size([35, 20, 200])\n",
      "torch.Size([35, 20, 300]) \t 2\n",
      "torch.Size([700, 33278])\n"
     ]
    }
   ],
   "source": [
    "output, hidden = model(x, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 33278]), torch.Size([2, 20, 300]), torch.Size([2, 20, 300]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hidden[0].shape, hidden[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.4171, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = criterion(output, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch, i in enumerate(range(0, train_data.size(0)-1, BPTT)):\n",
    "        data, targets = get_batch(train_data, BPTT, i)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.data.add_(p.grad.data, alpha=-LR)\n",
    "            \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch % LOG_INTERVAL == 0 and batch > 0:\n",
    "            cur_loss = total_loss / LOG_INTERVAL\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // BPTT, LR,\n",
    "                elapsed * 1000 / LOG_INTERVAL, cur_loss,\n",
    "                math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "\n",
    "def evaluate(data_source):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in enumerate(range(0, data_source.size(0)-1, BPTT)):\n",
    "            data, targets = get_batch(data_source, BPTT, i)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = criterion(output, targets)\n",
    "            total_loss += len(data) * loss.item()\n",
    "    return total_loss / data_source.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2965 batches | lr 20.00 | ms/batch 623.36 | loss  7.62 | ppl  2042.86\n",
      "| epoch   1 |   400/ 2965 batches | lr 20.00 | ms/batch 605.04 | loss  6.91 | ppl  1004.86\n",
      "| epoch   1 |   600/ 2965 batches | lr 20.00 | ms/batch 606.00 | loss  6.53 | ppl   684.63\n",
      "| epoch   1 |   800/ 2965 batches | lr 20.00 | ms/batch 604.76 | loss  6.33 | ppl   559.94\n",
      "| epoch   1 |  1000/ 2965 batches | lr 20.00 | ms/batch 624.70 | loss  6.16 | ppl   474.45\n",
      "| epoch   1 |  1200/ 2965 batches | lr 20.00 | ms/batch 664.46 | loss  6.08 | ppl   438.24\n",
      "| epoch   1 |  1400/ 2965 batches | lr 20.00 | ms/batch 634.43 | loss  5.95 | ppl   382.94\n",
      "| epoch   1 |  1600/ 2965 batches | lr 20.00 | ms/batch 647.06 | loss  5.94 | ppl   379.38\n",
      "| epoch   1 |  1800/ 2965 batches | lr 20.00 | ms/batch 634.25 | loss  5.79 | ppl   326.08\n",
      "| epoch   1 |  2000/ 2965 batches | lr 20.00 | ms/batch 683.86 | loss  5.74 | ppl   311.42\n",
      "| epoch   1 |  2200/ 2965 batches | lr 20.00 | ms/batch 679.16 | loss  5.63 | ppl   278.02\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "best_val_loss = sys.maxsize\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train()\n",
    "        val_loss = evaluate(val_data)\n",
    "        print('-' * 89)\n",
    "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "                'valid ppl {:8.2f}'.format(\n",
    "                    epoch, (time.time() - epoch_start_time),\n",
    "                    val_loss, math.exp(val_loss)))\n",
    "        print('-' * 89)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        else:\n",
    "            lr /= 4.0\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print('-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
