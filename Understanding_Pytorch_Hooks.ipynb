{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/sironghuang/understanding-pytorch-hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,2)\n",
    "        self.s1 = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(2,2)\n",
    "        self.s2 = nn.Sigmoid()\n",
    "        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n",
    "        self.fc1.bias = torch.nn.Parameter(torch.Tensor([0.35]))\n",
    "        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n",
    "        self.fc2.bias = torch.nn.Parameter(torch.Tensor([0.6]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x= self.fc1(x)\n",
    "        x = self.s1(x)\n",
    "        x= self.fc2(x)\n",
    "        x = self.s2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s1): Sigmoid()\n",
      "  (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (s2): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.1500, 0.2000],\n",
      "        [0.2500, 0.3000]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3500], requires_grad=True), Parameter containing:\n",
      "tensor([[0.4000, 0.4500],\n",
      "        [0.5000, 0.5500]], requires_grad=True), Parameter containing:\n",
      "tensor([0.6000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# parameters: weight and bias\n",
    "print(list(net.parameters()))\n",
    "# input data\n",
    "weight1 = list(net.parameters())[0]\n",
    "weight2 = list(net.parameters())[2]\n",
    "data = torch.Tensor([0.05,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.1500, 0.2000],\n",
       "         [0.2500, 0.3000]], requires_grad=True), Parameter containing:\n",
       " tensor([[0.4000, 0.4500],\n",
       "         [0.5000, 0.5500]], requires_grad=True))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight1, weight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2984, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of last layer\n",
    "out = net(data)\n",
    "target = torch.Tensor([0.01,0.99])  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target); loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple hook class that returns the input and output of a\n",
    "# layer during forward/backward pass\n",
    "\n",
    "class Hook():\n",
    "    def __init__(self, module, backward=False):\n",
    "        if backward==False:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('fc1', Linear(in_features=2, out_features=2, bias=True)), ('s1', Sigmoid()), ('fc2', Linear(in_features=2, out_features=2, bias=True)), ('s2', Sigmoid())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._modules.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register hooks on each layer\n",
    "hookF = [Hook(layer[1]) for layer in list(net._modules.items())]\n",
    "hookB = [Hook(layer[1],backward=True) for layer in\n",
    "         list(net._modules.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hook at 0x121c2e438>,\n",
       " <__main__.Hook at 0x121c2e6d8>,\n",
       " <__main__.Hook at 0x121c2e5c0>,\n",
       " <__main__.Hook at 0x121c2e668>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hookF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hook at 0x121c2e748>,\n",
       " <__main__.Hook at 0x121c2e7b8>,\n",
       " <__main__.Hook at 0x121c2e828>,\n",
       " <__main__.Hook at 0x121c2e898>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hookB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0500, 0.1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a data batch\n",
    "out=net(data)\n",
    "# backprop once to get the backward hook results\n",
    "out.backward(torch.tensor([1,1],dtype=torch.float),retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********  Forward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0500, 0.1000]),)\n",
      "tensor([0.3775, 0.3925], grad_fn=<AddBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.3775, 0.3925], grad_fn=<AddBackward0>),)\n",
      "tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward>)\n",
      "---------------------------------------------------\n",
      "(tensor([0.5933, 0.5969], grad_fn=<SigmoidBackward>),)\n",
      "tensor([1.1059, 1.2249], grad_fn=<AddBackward0>)\n",
      "---------------------------------------------------\n",
      "(tensor([1.1059, 1.2249], grad_fn=<AddBackward0>),)\n",
      "tensor([0.7514, 0.7729], grad_fn=<SigmoidBackward>)\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "*********  Backward Hooks Inputs & Outputs  *********\n",
      "(tensor([0.0392, 0.0435]), tensor([0.0827]))\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.0392, 0.0435]),)\n",
      "(tensor([0.1625, 0.1806]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]), tensor([0.3623]))\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "---------------------------------------------------\n",
      "(tensor([0.1868, 0.1755]),)\n",
      "(tensor([1., 1.]),)\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('***'*3+'  Forward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookF:\n",
    "    print(hook.input)\n",
    "    print(hook.output)\n",
    "    print('---'*17)\n",
    "print('\\n')\n",
    "print('***'*3+'  Backward Hooks Inputs & Outputs  '+'***'*3)\n",
    "for hook in hookB:             \n",
    "    print(hook.input)          \n",
    "    print(hook.output)         \n",
    "    print('---'*17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3775, 0.3925], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(weight1, data) + 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight1.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5933, 0.5969])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sigmoid()(tensor([0.3775, 0.3925]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5933, 0.5969])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1/(1+np.exp(-x)) for x in [0.3775, 0.3925]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1059, 1.2249], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(weight2, tensor([0.5933, 0.5969])) + 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7514, 0.7729])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor([1/(1+np.exp(-x)) for x in [1.1059, 1.2249]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18679804, 0.17552559])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the calculations with the print result above\n",
    "# the 4th layer - sigmoid\n",
    "forward_output = np.array([0.7514, 0.7729]) \n",
    "grad_in = np.array([1,1])  # sigmoid layer\n",
    "# grad of sigmoid(x) wrt x is: sigmoid(x)(1-sigmoid(x))\n",
    "grad_out = grad_in*(forward_output*(1-forward_output)); grad_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1868, 0.1755]\n",
      "0.36229999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1625, 0.1806]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 3th layer - linear\n",
    "print([0.1868, 0.1755])  # grad_input * (grad of Wx+b = (w1*x1+w2*x2)+b wrt W) \n",
    "print(0.1868 + 0.1755)   # grad of Wx+b wrt b o\n",
    "\n",
    "grad_in = torch.Tensor(grad_out)\n",
    "grad_out = grad_in.view(1,-1) @ weight2;grad_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Guided_backprop():\n",
    "    \"\"\"\n",
    "        Visualize CNN activation maps with guided backprop.\n",
    "        \n",
    "        Returns: An image that represent what the network learnt for recognizing \n",
    "        the given image. \n",
    "        \n",
    "        Methods: First layer input that minimize the error between the last layers output,\n",
    "        for the given class, and the true label(=1). \n",
    "        \n",
    "        ! Call visualize(image) to get the image representation\n",
    "    \"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.image_reconstruction = None\n",
    "        self.activation_maps = []\n",
    "        # eval mode\n",
    "        self.model.eval()\n",
    "        self.register_hooks()\n",
    "    \n",
    "    def register_hooks(self):\n",
    "        \n",
    "        def first_layer_hook_fn(module, grad_out, grad_in):\n",
    "            \"\"\" Return reconstructed activation image\"\"\"\n",
    "            self.image_reconstruction = grad_out[0] \n",
    "            \n",
    "        def forward_hook_fn(module, input, output):\n",
    "            \"\"\" Stores the forward pass outputs (activation maps)\"\"\"\n",
    "            self.activation_maps.append(output)\n",
    "            \n",
    "        def backward_hook_fn(module, grad_out, grad_in):\n",
    "            \"\"\" Output the grad of model output wrt. layer (only positive) \"\"\"\n",
    "            \n",
    "            # Gradient of forward_output wrt. forward_input = error of activation map:\n",
    "                # for relu layer: grad of zero = 0, grad of identity = 1\n",
    "            grad = self.activation_maps[-1] # corresponding forward pass output \n",
    "            grad[grad>0] = 1 # grad of relu when > 0\n",
    "            \n",
    "            # set negative output gradient to 0 #!???\n",
    "            positive_grad_out = torch.clamp(input=grad_out[0],min=0.0)\n",
    "            \n",
    "            # backward grad_out = grad_out * (grad of forward output wrt. forward input)\n",
    "            new_grad_out = positive_grad_out * grad\n",
    "            \n",
    "            del self.forward_outputs[-1] \n",
    "            \n",
    "            # For hook functions, the returned value will be the new grad_out\n",
    "            return (new_grad_out,)\n",
    "            \n",
    "        # !!!!!!!!!!!!!!!! change the modules !!!!!!!!!!!!!!!!!!\n",
    "        # only conv layers, no flattened fc linear layers\n",
    "        modules = list(self.model._modules.items())\n",
    "        \n",
    "        # register hooks to relu layers\n",
    "        for name, module in modules:\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                module.register_forward_hook(forward_hook_fn)\n",
    "                module.register_backward_hook(backward_hook_fn)\n",
    "        \n",
    "        # register hook to the first layer \n",
    "        first_layer = modules[0][1] \n",
    "        first_layer.register_backward_hook(first_layer_hook_fn)\n",
    "        \n",
    "    def visualize(self, input_image, target_class):\n",
    "        # last layer output\n",
    "        model_output = self.model(input_image)\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # only calculate gradients wrt. target class \n",
    "        # set the other classes to 0: eg. [0,0,1]\n",
    "        grad_target_map = torch.zeros(model_output.shape,\n",
    "                                     dtype=torch.float)\n",
    "        grad_target_map[0][target_class] = 1\n",
    "        \n",
    "        model_output.backward(grad_target_map)\n",
    "        \n",
    "        # Convert Pytorch variable to numpy array\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        result = self.image_reconstruction.data.numpy()[0] \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Linear(in_features=10, out_features=25, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=25, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05605903,  0.21413276,  0.03864008,  0.27759585, -0.0218803 ,\n",
       "        -0.27770042, -0.12772922,  0.21790203,  0.27921847,  0.17068928],\n",
       "       [ 0.2353166 , -0.30308807,  0.00965044, -0.05414191,  0.26118025,\n",
       "         0.22667179,  0.15487832,  0.07039323, -0.24430089, -0.13256349],\n",
       "       [ 0.02279872,  0.17414159, -0.01550066,  0.16892502, -0.27508423,\n",
       "         0.09690019,  0.09893283,  0.28091332, -0.30712515,  0.2810661 ],\n",
       "       [ 0.28747836, -0.18949239, -0.09113134,  0.09072161, -0.24991967,\n",
       "        -0.07525887,  0.3030893 , -0.2875347 ,  0.1885108 ,  0.06511906],\n",
       "       [ 0.20232043,  0.31575915, -0.11479175,  0.30545577, -0.02487636,\n",
       "         0.2835237 , -0.22868106, -0.10547651,  0.24900278, -0.2795855 ],\n",
       "       [-0.02803028, -0.20272726,  0.12217557, -0.26757693, -0.28732404,\n",
       "        -0.21200514,  0.29561362, -0.23897329, -0.02601784, -0.00986987],\n",
       "       [ 0.1934112 , -0.15400054, -0.28188467,  0.2531747 ,  0.10334834,\n",
       "        -0.31269288, -0.23567474, -0.15413313,  0.3076351 , -0.25574356],\n",
       "       [-0.26959115, -0.03417772, -0.1363324 ,  0.06835395, -0.27086645,\n",
       "         0.19822744, -0.17905657, -0.27792692,  0.29456785, -0.21019487],\n",
       "       [-0.29842952,  0.09740141, -0.19387828,  0.21193275, -0.25891656,\n",
       "        -0.218301  ,  0.22334781, -0.10043915, -0.2601498 ,  0.29397944],\n",
       "       [ 0.04476213, -0.15853503,  0.10795918, -0.20650533, -0.01439741,\n",
       "        -0.3041819 ,  0.30109772, -0.03861627, -0.15485623, -0.1406859 ],\n",
       "       [ 0.10028592, -0.1595647 , -0.27374348,  0.19282714,  0.1787957 ,\n",
       "        -0.2015878 , -0.00922793, -0.2509725 , -0.18139979, -0.15763588],\n",
       "       [ 0.01963291,  0.30608055, -0.01435331, -0.16049933, -0.07507418,\n",
       "        -0.21456158, -0.129884  , -0.19639276,  0.28349534,  0.26569673],\n",
       "       [ 0.10084888, -0.19310293,  0.31607285, -0.02033758, -0.02614465,\n",
       "        -0.08353323, -0.11224078, -0.03438985, -0.29171255, -0.29487672],\n",
       "       [ 0.1320689 ,  0.02831146, -0.03688505, -0.20497742,  0.20690688,\n",
       "        -0.06125131, -0.21573874,  0.25229308, -0.2617531 , -0.0090993 ],\n",
       "       [-0.12260847, -0.29834062, -0.02754608,  0.1575051 , -0.06475699,\n",
       "         0.23757204, -0.22474244, -0.15090525, -0.0062421 , -0.10188837],\n",
       "       [-0.2791333 , -0.19023718,  0.31355736,  0.05308554,  0.14258939,\n",
       "         0.17090094,  0.07698923,  0.02524364, -0.06300616, -0.08968543],\n",
       "       [-0.09310578,  0.16493827,  0.31219742,  0.23407075,  0.01180404,\n",
       "        -0.22457126, -0.11808962,  0.09455764,  0.06570846, -0.03001511],\n",
       "       [ 0.16149688, -0.08367302,  0.12902108, -0.21932104, -0.17646058,\n",
       "        -0.02562016, -0.19369228,  0.24195406, -0.24677584,  0.22289261],\n",
       "       [ 0.22056714,  0.30690297, -0.2802198 , -0.06641044,  0.30811474,\n",
       "         0.06707707, -0.23116142, -0.14057127, -0.10388449, -0.03095946],\n",
       "       [ 0.10022938,  0.00197667,  0.24589303, -0.15202309, -0.12245421,\n",
       "         0.22889873, -0.272007  , -0.3030747 , -0.2559362 , -0.14286989],\n",
       "       [ 0.15260658,  0.30813602, -0.08063009,  0.09835276,  0.29645917,\n",
       "         0.00393146,  0.12750244,  0.19675055,  0.02576873,  0.27639243],\n",
       "       [-0.25988966,  0.30884668,  0.02768862, -0.00584871, -0.09704612,\n",
       "         0.307422  , -0.19155568,  0.16564289, -0.23501971,  0.18334031],\n",
       "       [-0.2719653 ,  0.28366753, -0.17787296, -0.12914532,  0.22959545,\n",
       "        -0.24711978, -0.18595122, -0.04884946,  0.09569144,  0.3115801 ],\n",
       "       [ 0.04416883,  0.27200803, -0.12624732,  0.28420255, -0.19827488,\n",
       "         0.04230776,  0.26440778,  0.23877326,  0.27345827,  0.3007624 ],\n",
       "       [ 0.13857108, -0.10870209, -0.27605018, -0.15967599, -0.02638674,\n",
       "        -0.01053631, -0.20643431, -0.0764363 , -0.15669677, -0.2033962 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model[0].weight.data.numpy()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x121cdc0b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].register_forward_hook(get_activation('layer0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 10)\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2664,  0.1553]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer0': tensor([[ 0.4767, -0.4778,  0.9047,  0.3566,  0.8153,  0.3330, -1.0060,  0.2747,\n",
       "          -0.8791, -0.2744, -1.6638,  0.2836, -0.2930, -0.4283, -0.4425, -0.2168,\n",
       "           0.1127,  0.5815, -0.3185,  0.7084, -0.2239,  0.5016, -0.6931,  0.9401,\n",
       "          -0.5919]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(activations['layer0'].shape)\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.matshow(activations['layer0'])\n",
    "plt.matshow(weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('0', Linear(in_features=10, out_features=25, bias=True)), ('1', ReLU()), ('2', Linear(in_features=25, out_features=2, bias=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 2)\n",
    ")\n",
    "\n",
    "\n",
    "visualisation = {}\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "    visualisation[str(m)] = o.detach().numpy()\n",
    "\n",
    "def get_all_layers(model):\n",
    "    for name, layer in model._modules.items():\n",
    "        layer.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=25, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=25, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear(in_features=10, out_features=25, bias=True)': array([[ 0.00316985, -0.08310953,  0.54357266,  0.7405807 , -0.16417319,\n",
       "          0.385947  ,  0.8438901 ,  0.38129696,  0.46040848, -0.11029162,\n",
       "          0.0388878 , -0.04883998, -0.11077804, -0.1817394 , -0.14541033,\n",
       "         -0.23613755,  0.32240853, -0.2988292 , -0.11823373,  0.2651435 ,\n",
       "         -0.7618786 ,  0.5321647 ,  0.12714799,  0.5923781 ,  0.55662835]],\n",
       "       dtype=float32),\n",
       " 'ReLU()': array([[0.00316985, 0.        , 0.54357266, 0.7405807 , 0.        ,\n",
       "         0.385947  , 0.8438901 , 0.38129696, 0.46040848, 0.        ,\n",
       "         0.0388878 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32240853, 0.        , 0.        , 0.2651435 ,\n",
       "         0.        , 0.5321647 , 0.12714799, 0.5923781 , 0.55662835]],\n",
       "       dtype=float32),\n",
       " 'Linear(in_features=25, out_features=2, bias=True)': array([[-0.6169652 ,  0.28780353]], dtype=float32)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out1 = visualisation['Linear(in_features=10, out_features=25, bias=True)']\n",
    "out1 = out1.reshape(-1)\n",
    "print(out1.shape)\n",
    "plt.hist(out1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
